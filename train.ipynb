{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 23:37:08.233758: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-30 23:37:08.268266: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-30 23:37:08.268772: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-30 23:37:08.898735: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.load('3d_rendering_x.npy')\n",
    "x2 = np.load('digit_recognition_x.npy')\n",
    "x3 = np.load('spam_filter_x.npy')\n",
    "\n",
    "y1 = np.load('3d_rendering_y.npy')\n",
    "y2 = np.load('digit_recognition_y.npy')\n",
    "y3 = np.load('spam_filter_y.npy')\n",
    "\n",
    "x = np.concatenate((x1,x2,x3), axis=0)\n",
    "y = np.concatenate((y1,y2,y3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_selection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/aamod/Desktop/FPGA-Proj/train.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/aamod/Desktop/FPGA-Proj/train.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_x, test_x, train_y, test_y \u001b[39m=\u001b[39m model_selection\u001b[39m.\u001b[39mtrain_test_split(X,Y,test_size \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m, random_state \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_selection' is not defined"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(X,Y,test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x = x\n",
    "te_x = x\n",
    "\n",
    "tr_y = y\n",
    "te_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 23:37:25.144347: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-30 23:37:25.147641: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 415ms/step - loss: 1.1277 - accuracy: 0.1500\n",
      "Epoch 2/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1020 - accuracy: 0.2000\n",
      "Epoch 3/55\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0784 - accuracy: 0.2000\n",
      "Epoch 4/55\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0555 - accuracy: 0.2500\n",
      "Epoch 5/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0335 - accuracy: 0.4000\n",
      "Epoch 6/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0125 - accuracy: 0.6000\n",
      "Epoch 7/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9919 - accuracy: 0.6500\n",
      "Epoch 8/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9720 - accuracy: 0.6500\n",
      "Epoch 9/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9527 - accuracy: 0.6500\n",
      "Epoch 10/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9340 - accuracy: 0.6500\n",
      "Epoch 11/55\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9163 - accuracy: 0.7000\n",
      "Epoch 12/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8990 - accuracy: 0.7000\n",
      "Epoch 13/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8820 - accuracy: 0.7000\n",
      "Epoch 14/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8654 - accuracy: 0.7000\n",
      "Epoch 15/55\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8493 - accuracy: 0.7000\n",
      "Epoch 16/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8338 - accuracy: 0.7000\n",
      "Epoch 17/55\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8188 - accuracy: 0.7000\n",
      "Epoch 18/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8043 - accuracy: 0.7000\n",
      "Epoch 19/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7900 - accuracy: 0.7000\n",
      "Epoch 20/55\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7761 - accuracy: 0.7500\n",
      "Epoch 21/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7622 - accuracy: 0.8000\n",
      "Epoch 22/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7485 - accuracy: 0.8000\n",
      "Epoch 23/55\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7350 - accuracy: 0.8000\n",
      "Epoch 24/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7217 - accuracy: 0.8000\n",
      "Epoch 25/55\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7087 - accuracy: 0.8000\n",
      "Epoch 26/55\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6959 - accuracy: 0.8000\n",
      "Epoch 27/55\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6832 - accuracy: 0.8000\n",
      "Epoch 28/55\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6708 - accuracy: 0.8000\n",
      "Epoch 29/55\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6586 - accuracy: 0.8000\n",
      "Epoch 30/55\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6466 - accuracy: 0.8000\n",
      "Epoch 31/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.8000\n",
      "Epoch 32/55\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6238 - accuracy: 0.8000\n",
      "Epoch 33/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.8000\n",
      "Epoch 34/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.8000\n",
      "Epoch 35/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.8000\n",
      "Epoch 36/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.8000\n",
      "Epoch 37/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7500\n",
      "Epoch 38/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5579 - accuracy: 0.7500\n",
      "Epoch 39/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.7500\n",
      "Epoch 40/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7500\n",
      "Epoch 41/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7500\n",
      "Epoch 42/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7500\n",
      "Epoch 43/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7500\n",
      "Epoch 44/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5010 - accuracy: 0.7500\n",
      "Epoch 45/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7500\n",
      "Epoch 46/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7500\n",
      "Epoch 47/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7500\n",
      "Epoch 48/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7500\n",
      "Epoch 49/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7500\n",
      "Epoch 50/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7500\n",
      "Epoch 51/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7500\n",
      "Epoch 52/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7500\n",
      "Epoch 53/55\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7500\n",
      "Epoch 54/55\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7500\n",
      "Epoch 55/55\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.4051 - accuracy: 0.7500\n",
      "\n",
      "accuracy: 75.00%\n"
     ]
    }
   ],
   "source": [
    "# def baseline_model():\n",
    "    # Create model here\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim = 64, activation = 'relu')) # Rectified Linear Unit Activation Function\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(3, activation = 'softmax')) # Softmax for multi-class classification\n",
    "    # Compile model here\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(tr_x, tr_y, epochs = 55)\n",
    "\n",
    "scores = model.evaluate(te_x, te_y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    # return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2659 (10.39 KB)\n",
      "Trainable params: 2659 (10.39 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aamod/.local/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('nnmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xGemm = np.load('gemm_x.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xGemm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.2451876 , 0.6835485 , 0.07126386],\n",
       "       [0.19465807, 0.70958877, 0.09575318],\n",
       "       [0.18232717, 0.7568289 , 0.06084402]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(xGemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def givePragma(x , model):\n",
    "    y = []\n",
    "    preds = model.predict(x)\n",
    "    for pred in preds:\n",
    "        if (np.argmax(pred)) == 0:\n",
    "            y.append(\"No Pragma\")\n",
    "        elif (np.argmax(pred)) == 1:\n",
    "            y.append(\"Pipeline Pragma\")\n",
    "        elif (np.argmax(pred)) == 2:\n",
    "            y.append(\"Unroll Pragma\")\n",
    "    \n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycheck = np.load('digit_recognition_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ycheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Pipeline Pragma', 'Pipeline Pragma', 'Pipeline Pragma']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "givePragma(xGemm , model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
